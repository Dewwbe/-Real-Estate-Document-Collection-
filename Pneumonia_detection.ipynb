{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vr_3pz0zu_FQJyQl6PsDn7xjyxETQPUH",
      "authorship_tag": "ABX9TyPAMwVZCamTodAh9Pkj/lWe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dewwbe/-Real-Estate-Document-Collection-/blob/main/Pneumonia_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =========================\n",
        "# DenseNet121 — Chest X-ray Pneumonia (PyTorch)\n",
        "# Metrics: Accuracy, Precision, Recall, F1, Confusion Matrix, ROC-AUC\n",
        "# Curves: Training vs Validation Loss/Accuracy\n",
        "# ========================="
      ],
      "metadata": {
        "id": "_97KNH91Aviy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Flxp6dLAyA8t"
      },
      "outputs": [],
      "source": [
        "# Core\n",
        "import os, copy, time, math, random, warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models"
      ],
      "metadata": {
        "id": "RZVe-O4yA3ZK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data / Viz\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ZT-qX3f3A736"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UHsi-8pkAtvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, roc_auc_score, roc_curve\n",
        ")"
      ],
      "metadata": {
        "id": "eXPE-ImlA-t6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== Config ==============\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ataet77NA_oy",
        "outputId": "7955042b-2793-4355-d269-6630cdb76944"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# >>>>>>> CHANGE THIS TO YOUR DATA ROOT (contains train/ val/ test/) <<<<<<<\n",
        "DATA_DIR = '/content/drive/MyDrive/chest_xray'  # or '/path/to/chest_xray'\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
        "VAL_DIR   = os.path.join(DATA_DIR, 'val')\n",
        "TEST_DIR  = os.path.join(DATA_DIR, 'test')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "EPOCHS = 20\n",
        "PATIENCE = 5\n",
        "LR = 1e-4\n",
        "CHECKPOINT_PATH = 'densenet121_pneumonia_best.pth'"
      ],
      "metadata": {
        "id": "e1Meb1D5BDgL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== Transforms & Data ==============\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.85, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.05, contrast=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "testval_tfms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(TRAIN_DIR, transform=train_tfms)\n",
        "val_ds   = datasets.ImageFolder(VAL_DIR,   transform=testval_tfms)\n",
        "test_ds  = datasets.ImageFolder(TEST_DIR,  transform=testval_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "class_names = train_ds.classes\n",
        "print(\"Classes:\", class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u9WLYswBHaj",
        "outputId": "39f19b9c-db4f-48c5-b085-0c679ca66ee7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['NORMAL', 'PNEUMONIA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== Class Imbalance (Weights) ==============\n",
        "targets = np.array(train_ds.targets)  # list of 0/1 labels\n",
        "class_counts = np.bincount(targets)\n",
        "# pos_weight for BCEWithLogitsLoss is (#neg / #pos)\n",
        "pos_weight = torch.tensor(class_counts[0] / max(1, class_counts[1]), dtype=torch.float32, device=DEVICE)\n",
        "print(\"Train class counts:\", class_counts, \" -> pos_weight:\", float(pos_weight))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6F4_fj5BO1a",
        "outputId": "6ade4b33-b427-4e2a-ebcc-4478c53d4fa0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train class counts: [1341 3875]  -> pos_weight: 0.3460645079612732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== DenseNet121 ==============\n",
        "model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
        "in_feats = model.classifier.in_features\n",
        "model.classifier = nn.Linear(in_feats, 1)  # single logit for binary\n",
        "model = model.to(DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pIXA5VdBTj7",
        "outputId": "d7efbbe1-c638-47a5-945c-a5a732aab31f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 126MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) Fine-tuning strategy: unfreeze last dense block + norm5\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "for name, p in model.features.named_parameters():\n",
        "    if \"denseblock4\" in name or \"norm5\" in name:\n",
        "        p.requires_grad = True\n",
        "# Always train classifier\n",
        "for p in model.classifier.parameters():\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "UQcUF3MSBV5h"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== Loss, Optim, Scheduler ==============\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # handles imbalance\n",
        "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.3)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "u-mjd6iWBW6S"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== Train/Val Loop ==============\n",
        "def run_epoch(loader, train_mode=True):\n",
        "    model.train(mode=train_mode)\n",
        "    total_loss = 0.0\n",
        "    y_true, y_prob = [], []\n",
        "    if train_mode:\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(DEVICE, non_blocking=True)\n",
        "        labels = labels.float().unsqueeze(1).to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.set_grad_enabled(train_mode):\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                logits = model(images)\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "            if train_mode:\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "        probs = torch.sigmoid(logits).detach().cpu().numpy().ravel()\n",
        "        y_prob.extend(probs.tolist())\n",
        "        y_true.extend(labels.detach().cpu().numpy().ravel().tolist())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    y_prob = np.array(y_prob)\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "    try:\n",
        "        auc  = roc_auc_score(y_true, y_prob)\n",
        "    except ValueError:\n",
        "        auc = float('nan')\n",
        "\n",
        "    return avg_loss, acc, prec, rec, f1, auc, y_true, y_prob, y_pred\n",
        "\n",
        "def fit(epochs=EPOCHS, patience=PATIENCE, ckpt_path=CHECKPOINT_PATH):\n",
        "    best_w = copy.deepcopy(model.state_dict())\n",
        "    best_val = math.inf\n",
        "    wait = 0\n",
        "\n",
        "    history = {'train_loss':[], 'val_loss':[], 'train_acc':[], 'val_acc':[]}\n",
        "\n",
        "    start = time.time()\n",
        "    for ep in range(1, epochs+1):\n",
        "        tl, ta, _, _, _, _, _, _, _ = run_epoch(train_loader, train_mode=True)\n",
        "        vl, va, vp, vrc, vf1, vauc, _, _, _ = run_epoch(val_loader,   train_mode=False)\n",
        "        scheduler.step(vl)\n",
        "\n",
        "        history['train_loss'].append(tl); history['val_loss'].append(vl)\n",
        "        history['train_acc'].append(ta);  history['val_acc'].append(va)\n",
        "\n",
        "        print(f\"[{ep:02d}/{epochs}] Train loss {tl:.4f} acc {ta:.3f} | \"\n",
        "              f\"Val loss {vl:.4f} acc {va:.3f} (P {vp:.3f} R {vrc:.3f} F1 {vf1:.3f} AUC {vauc:.3f})\")\n",
        "\n",
        "        if vl < best_val:\n",
        "            best_val = vl; wait = 0\n",
        "            best_w = copy.deepcopy(model.state_dict())\n",
        "            torch.save({'model':'densenet121','state_dict':best_w}, ckpt_path)\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"Early stopping at epoch {ep}. Best val loss: {best_val:.4f}\")\n",
        "                break\n",
        "\n",
        "    total_time = time.time() - start\n",
        "    print(f\"Training complete in {total_time/60:.1f} min. Best val loss: {best_val:.4f}\")\n",
        "    model.load_state_dict(best_w)\n",
        "    return history\n",
        "\n",
        "history = fit()\n"
      ],
      "metadata": {
        "id": "Nt7SZnMhBZrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== Train/Val Loop ==============\n",
        "def run_epoch(loader, train_mode=True):\n",
        "    model.train(mode=train_mode)\n",
        "    total_loss = 0.0\n",
        "    y_true, y_prob = [], []\n",
        "    if train_mode:\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(DEVICE, non_blocking=True)\n",
        "        labels = labels.float().unsqueeze(1).to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.set_grad_enabled(train_mode):\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                logits = model(images)\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "            if train_mode:\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "        probs = torch.sigmoid(logits).detach().cpu().numpy().ravel()\n",
        "        y_prob.extend(probs.tolist())\n",
        "        y_true.extend(labels.detach().cpu().numpy().ravel().tolist())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    y_prob = np.array(y_prob)\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "    try:\n",
        "        auc  = roc_auc_score(y_true, y_prob)\n",
        "    except ValueError:\n",
        "        auc = float('nan')\n",
        "\n",
        "    return avg_loss, acc, prec, rec, f1, auc, y_true, y_prob, y_pred\n",
        "\n",
        "def fit(epochs=EPOCHS, patience=PATIENCE, ckpt_path=CHECKPOINT_PATH):\n",
        "    best_w = copy.deepcopy(model.state_dict())\n",
        "    best_val = math.inf\n",
        "    wait = 0\n",
        "\n",
        "    history = {'train_loss':[], 'val_loss':[], 'train_acc':[], 'val_acc':[]}\n",
        "\n",
        "    start = time.time()\n",
        "    for ep in range(1, epochs+1):\n",
        "        tl, ta, _, _, _, _, _, _, _ = run_epoch(train_loader, train_mode=True)\n",
        "        vl, va, vp, vrc, vf1, vauc, _, _, _ = run_epoch(val_loader,   train_mode=False)\n",
        "        scheduler.step(vl)\n",
        "\n",
        "        history['train_loss'].append(tl); history['val_loss'].append(vl)\n",
        "        history['train_acc'].append(ta);  history['val_acc'].append(va)\n",
        "\n",
        "        print(f\"[{ep:02d}/{epochs}] Train loss {tl:.4f} acc {ta:.3f} | \"\n",
        "              f\"Val loss {vl:.4f} acc {va:.3f} (P {vp:.3f} R {vrc:.3f} F1 {vf1:.3f} AUC {vauc:.3f})\")\n",
        "\n",
        "        if vl < best_val:\n",
        "            best_val = vl; wait = 0\n",
        "            best_w = copy.deepcopy(model.state_dict())\n",
        "            torch.save({'model':'densenet121','state_dict':best_w}, ckpt_path)\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"Early stopping at epoch {ep}. Best val loss: {best_val:.4f}\")\n",
        "                break\n",
        "\n",
        "    total_time = time.time() - start\n",
        "    print(f\"Training complete in {total_time/60:.1f} min. Best val loss: {best_val:.4f}\")\n",
        "    model.load_state_dict(best_w)\n",
        "    return history\n",
        "\n",
        "history = fit()\n"
      ],
      "metadata": {
        "id": "EvjSNuIgBeIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== Test Evaluation ==============\n",
        "def evaluate_test():\n",
        "    tl, acc, prec, rec, f1, auc, y_true, y_prob, y_pred = run_epoch(test_loader, train_mode=False)\n",
        "\n",
        "    print(\"\\n=== Test Metrics (DenseNet121) ===\")\n",
        "    print(f\"Loss: {tl:.4f}\")\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    print(f\"ROC-AUC:   {auc:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "    # Plot Confusion Matrix\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title('Confusion Matrix'); plt.colorbar()\n",
        "    tick_marks = np.arange(2)\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                     ha=\"center\", va=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(fpr, tpr, lw=2)\n",
        "    plt.plot([0,1],[0,1],'--')\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve (AUC={auc:.3f})')\n",
        "    plt.grid(True, ls='--', alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'test_loss': tl, 'accuracy': acc, 'precision': prec,\n",
        "        'recall': rec, 'f1': f1, 'auc': auc\n",
        "    }\n",
        "\n",
        "# Load best weights (safety) and evaluate\n",
        "ckpt = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
        "model.load_state_dict(ckpt['state_dict'])\n",
        "test_results = evaluate_test()\n",
        "print(\"\\nSummary:\", test_results)"
      ],
      "metadata": {
        "id": "aP-zEBdWBhrj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}